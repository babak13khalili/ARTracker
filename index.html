<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <title>Advanced AR Tracker</title>
    <style>
      :root {
        --ui-white: rgba(255, 255, 255, 0.9);
        --ui-bg: rgba(0, 0, 0, 0.85);
        --accent: #00ffcc;
      }

      body,
      html {
        margin: 0;
        padding: 0;
        width: 100%;
        height: 100%;
        background: #000;
        overflow: hidden;
        font-family: sans-serif;
      }

      /* Container Setup */
      .ar-container {
        position: relative;
        width: 100vw;
        height: 100vh;
        display: flex;
        justify-content: center;
      }
      video,
      canvas {
        position: absolute;
        width: 100%;
        height: 100%;
        object-fit: contain;
      }

      /* Overlay Interface */
      #overlay {
        position: absolute;
        inset: 0;
        background: #000;
        z-index: 100;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        transition: opacity 0.6s ease;
      }
      #overlay h1 {
        font-weight: 100;
        font-size: 2.5rem;
        letter-spacing: 8px;
        color: white;
      }
      .btn-main {
        margin-top: 2rem;
        padding: 1rem 2.5rem;
        background: none;
        border: 1px solid var(--ui-white);
        color: white;
        cursor: pointer;
        letter-spacing: 2px;
        font-size: 0.9rem;
        transition: 0.3s;
      }
      .btn-main:hover {
        background: white;
        color: black;
      }

      /* Controls Area */
      .controls {
        position: absolute;
        bottom: 10%;
        width: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 1rem;
        z-index: 10;
      }
      #status {
        color: var(--ui-white);
        font-size: 0.7rem;
        letter-spacing: 2px;
        text-transform: uppercase;
      }
      .btn-record {
        width: 60px;
        height: 60px;
        border-radius: 50%;
        border: 2px solid white;
        background: none;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
      }
      .btn-record .inner {
        width: 20px;
        height: 20px;
        background: red;
        border-radius: 50%;
        transition: 0.3s;
      }
      .btn-record.active .inner {
        background: white;
        border-radius: 2px;
      }
    </style>
  </head>
  <body>
    <div class="ar-container">
      <div id="overlay">
        <h1>SPATIAL AR</h1>
        <p style="color: #666; font-weight: 300">
          Point at a cup to begin tracking
        </p>
        <button class="btn-main" onclick="startApp()">INITIALIZE ENGINE</button>
      </div>

      <video id="webcam" autoplay playsinline></video>
      <canvas id="output_canvas"></canvas>

      <div class="controls">
        <div id="status">Engine Ready</div>
        <button id="record-btn" class="btn-record" onclick="toggleTracking()">
          <div class="inner"></div>
        </button>
      </div>
    </div>

    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"
      crossorigin="anonymous"></script>

    <script type="module">
      import {
        ObjectDetector,
        FilesetResolver,
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js";

      const video = document.getElementById("webcam");
      const canvas = document.getElementById("output_canvas");
      const ctx = canvas.getContext("2d");
      const recordBtn = document.getElementById("record-btn");
      const statusDiv = document.getElementById("status");

      let objectDetector;
      let isTracking = false;
      let pathData = []; // Stores {x, y, size}

      window.startApp = async () => {
        document.getElementById("overlay").style.opacity = "0";
        setTimeout(
          () => (document.getElementById("overlay").style.display = "none"),
          600,
        );

        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm",
        );
        objectDetector = await ObjectDetector.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite`,
            delegate: "GPU",
          },
          scoreThreshold: 0.4,
          runningMode: "VIDEO",
        });
        startCamera();
      };

      window.toggleTracking = () => {
        isTracking = !isTracking;
        recordBtn.classList.toggle("active");
        statusDiv.innerText = isTracking ? "Recording Path..." : "Paused";
        if (!isTracking) pathData = []; // Optional: Clear path on stop
      };

      async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
        });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          predictWebcam();
        };
      }

      function predictWebcam() {
        if (objectDetector && video.readyState >= 2) {
          const detections = objectDetector.detectForVideo(
            video,
            performance.now(),
          );
          drawScene(detections);
        }
        window.requestAnimationFrame(predictWebcam);
      }

      function drawScene(result) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        result.detections.forEach((detection) => {
          const { originX, originY, width, height } = detection.boundingBox;
          const label = detection.categories[0].categoryName;

          // 1. Draw Bounding Box (Live detection)
          ctx.strokeStyle = "rgba(255, 255, 255, 0.4)";
          ctx.lineWidth = 1;
          ctx.strokeRect(originX, originY, width, height);

          // 2. Add to Path if tracking is ON
          if (isTracking && label === "cup") {
            const centerX = originX + width / 2;
            const centerY = originY + height;
            // Store position + size (size is used as a depth proxy)
            pathData.push({ x: centerX, y: centerY, size: width });
            if (pathData.length > 200) pathData.shift();
          }
        });

        // 3. Draw Spatial Path
        if (pathData.length > 2) {
          for (let i = 1; i < pathData.length; i++) {
            const p1 = pathData[i - 1];
            const p2 = pathData[i];

            // DEPTH EFFECT: Thickness changes based on the object's width
            const thickness = Math.max(1, p2.size / 30);
            const opacity = Math.min(1, p2.size / 100);

            ctx.beginPath();
            ctx.strokeStyle = `rgba(255, 255, 255, ${opacity})`;
            ctx.lineWidth = thickness;
            ctx.lineCap = "round";
            ctx.moveTo(p1.x, p1.y);
            ctx.lineTo(p2.x, p2.y);
            ctx.stroke();
          }
        }
      }
    </script>
  </body>
</html>
